{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 — Data Preprocessing\n",
    "### CSC 577 | Team Rocket | Food.com Recipe Recommender\n",
    "\n",
    "This notebook cleans and filters the raw data based on decisions made in `01_EDA.ipynb`.\n",
    "\n",
    "**Steps:**\n",
    "1. Load raw data\n",
    "2. Clean interactions (remove zero ratings, duplicates)\n",
    "3. Filter to active users (≥ 10 ratings) and popular recipes (≥ 5 ratings)\n",
    "4. Clean and parse recipe metadata (ingredients, tags, nutrition)\n",
    "5. Merge and align the two datasets\n",
    "6. Save processed files to `data/processed/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import os\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "print('Libraries loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw recipes shape:      (231637, 12)\n",
      "Raw interactions shape: (1132367, 5)\n"
     ]
    }
   ],
   "source": [
    "recipes_raw = pd.read_csv('../data/RAW_recipes.csv')\n",
    "interactions_raw = pd.read_csv('../data/RAW_interactions.csv')\n",
    "\n",
    "print(f'Raw recipes shape:      {recipes_raw.shape}')\n",
    "print(f'Raw interactions shape: {interactions_raw.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean Interactions\n",
    "\n",
    "### 2a. Remove zero ratings\n",
    "A rating of `0` on Food.com means the user left a text review but did NOT give a star rating. These are not valid for our recommender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 60,847 zero-rating rows\n",
      "Interactions remaining: 1,071,520\n"
     ]
    }
   ],
   "source": [
    "interactions = interactions_raw[interactions_raw['rating'] > 0].copy()\n",
    "\n",
    "removed_zeros = len(interactions_raw) - len(interactions)\n",
    "print(f'Removed {removed_zeros:,} zero-rating rows')\n",
    "print(f'Interactions remaining: {len(interactions):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Remove duplicate interactions\n",
    "Keep the most recent rating if a user rated the same recipe more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing duplicates: 1,071,520 interactions\n"
     ]
    }
   ],
   "source": [
    "# Sort by date descending so keep='first' keeps the most recent\n",
    "interactions['date'] = pd.to_datetime(interactions['date'])\n",
    "interactions = interactions.sort_values('date', ascending=False)\n",
    "interactions = interactions.drop_duplicates(subset=['user_id', 'recipe_id'], keep='first')\n",
    "\n",
    "print(f'After removing duplicates: {len(interactions):,} interactions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filter Active Users and Popular Recipes\n",
    "\n",
    "We apply iterative filtering — removing sparse users and recipes in turns — until the dataset stabilizes. This is standard practice to ensure the CF model has enough signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying iterative filtering...\n",
      "  Iteration 1: 1,071,520 → 498,242 interactions\n",
      "  Iteration 2: 498,242 → 472,335 interactions\n",
      "  Iteration 3: 472,335 → 471,334 interactions\n",
      "  Iteration 4: 471,334 → 471,303 interactions\n",
      "  Iteration 5: 471,303 → 471,303 interactions\n",
      "  Converged.\n",
      "\n",
      "Final interactions: 471,303\n",
      "Unique users:       9,087\n",
      "Unique recipes:     36,916\n"
     ]
    }
   ],
   "source": [
    "MIN_USER_RATINGS   = 10   # minimum ratings a user must have\n",
    "MIN_RECIPE_RATINGS = 5    # minimum ratings a recipe must have\n",
    "\n",
    "def filter_interactions(df, min_user, min_recipe):\n",
    "    \"\"\"Iteratively filter until no users or recipes fall below the threshold.\"\"\"\n",
    "    iteration = 0\n",
    "    while True:\n",
    "        iteration += 1\n",
    "        start_size = len(df)\n",
    "\n",
    "        # Filter users\n",
    "        user_counts = df['user_id'].value_counts()\n",
    "        valid_users = user_counts[user_counts >= min_user].index\n",
    "        df = df[df['user_id'].isin(valid_users)]\n",
    "\n",
    "        # Filter recipes\n",
    "        recipe_counts = df['recipe_id'].value_counts()\n",
    "        valid_recipes = recipe_counts[recipe_counts >= min_recipe].index\n",
    "        df = df[df['recipe_id'].isin(valid_recipes)]\n",
    "\n",
    "        end_size = len(df)\n",
    "        print(f'  Iteration {iteration}: {start_size:,} → {end_size:,} interactions')\n",
    "\n",
    "        if start_size == end_size:\n",
    "            print('  Converged.')\n",
    "            break\n",
    "\n",
    "    return df\n",
    "\n",
    "print('Applying iterative filtering...')\n",
    "interactions_filtered = filter_interactions(interactions.copy(), MIN_USER_RATINGS, MIN_RECIPE_RATINGS)\n",
    "\n",
    "print(f'\\nFinal interactions: {len(interactions_filtered):,}')\n",
    "print(f'Unique users:       {interactions_filtered[\"user_id\"].nunique():,}')\n",
    "print(f'Unique recipes:     {interactions_filtered[\"recipe_id\"].nunique():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min ratings per user:   10\n",
      "Max ratings per user:   2712\n",
      "Min ratings per recipe: 5\n",
      "Max ratings per recipe: 780\n",
      "\n",
      "All threshold checks passed.\n"
     ]
    }
   ],
   "source": [
    "# Verify thresholds were met\n",
    "user_rating_counts   = interactions_filtered['user_id'].value_counts()\n",
    "recipe_rating_counts = interactions_filtered['recipe_id'].value_counts()\n",
    "\n",
    "assert user_rating_counts.min() >= MIN_USER_RATINGS, 'Some users below threshold!'\n",
    "assert recipe_rating_counts.min() >= MIN_RECIPE_RATINGS, 'Some recipes below threshold!'\n",
    "\n",
    "print(f'Min ratings per user:   {user_rating_counts.min()}')\n",
    "print(f'Max ratings per user:   {user_rating_counts.max()}')\n",
    "print(f'Min ratings per recipe: {recipe_rating_counts.min()}')\n",
    "print(f'Max ratings per recipe: {recipe_rating_counts.max()}')\n",
    "print('\\nAll threshold checks passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clean Recipe Metadata\n",
    "\n",
    "### 4a. Keep only recipes that appear in filtered interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipes kept: 36,916 out of 231,637\n"
     ]
    }
   ],
   "source": [
    "valid_recipe_ids = interactions_filtered['recipe_id'].unique()\n",
    "recipes = recipes_raw[recipes_raw['id'].isin(valid_recipe_ids)].copy()\n",
    "\n",
    "print(f'Recipes kept: {len(recipes):,} out of {len(recipes_raw):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Parse stringified list columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed: ingredients, tags, steps\n",
      "Example ingredients for first recipe:\n",
      "['lean pork chops', 'flour', 'salt', 'dry mustard', 'garlic powder', 'oil', 'chicken rice soup']\n"
     ]
    }
   ],
   "source": [
    "def safe_parse_list(x):\n",
    "    \"\"\"Safely parse a stringified Python list.\"\"\"\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "recipes['ingredients'] = recipes['ingredients'].apply(safe_parse_list)\n",
    "recipes['tags']        = recipes['tags'].apply(safe_parse_list)\n",
    "recipes['steps']       = recipes['steps'].apply(safe_parse_list)\n",
    "\n",
    "print('Parsed: ingredients, tags, steps')\n",
    "print(f'Example ingredients for first recipe:')\n",
    "print(recipes['ingredients'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. Parse nutrition column\n",
    "\n",
    "Nutrition is stored as `[calories, total_fat_%DV, sugar_%DV, sodium_%DV, protein_%DV, sat_fat_%DV, carbs_%DV]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nutrition columns added:\n",
      "       calories  total_fat_pdv  sugar_pdv  sodium_pdv  protein_pdv  \\\n",
      "count  36916.00       36916.00   36916.00    36916.00     36916.00   \n",
      "mean     431.51          32.51      70.65       29.64        33.49   \n",
      "std      665.59          64.74     202.72      106.20        64.57   \n",
      "min        0.00           0.00       0.00        0.00         0.00   \n",
      "25%      167.50           8.00       8.00        5.00         6.00   \n",
      "50%      294.80          19.00      22.00       15.00        17.00   \n",
      "75%      483.62          38.00      60.00       33.00        50.00   \n",
      "max    38680.10        4331.00    8320.00     7084.00      6552.00   \n",
      "\n",
      "       sat_fat_pdv  carbs_pdv  \n",
      "count     36916.00   36916.00  \n",
      "mean         40.99      13.93  \n",
      "std          84.91      26.31  \n",
      "min           0.00       0.00  \n",
      "25%           7.00       3.00  \n",
      "50%          21.00       8.00  \n",
      "75%          49.00      15.00  \n",
      "max        4969.00    1188.00  \n"
     ]
    }
   ],
   "source": [
    "nutrition_cols = ['calories', 'total_fat_pdv', 'sugar_pdv', 'sodium_pdv',\n",
    "                  'protein_pdv', 'sat_fat_pdv', 'carbs_pdv']\n",
    "\n",
    "nutrition_parsed = recipes['nutrition'].apply(safe_parse_list)\n",
    "recipes[nutrition_cols] = pd.DataFrame(nutrition_parsed.tolist(), index=recipes.index)\n",
    "\n",
    "print('Nutrition columns added:')\n",
    "print(recipes[nutrition_cols].describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4d. Handle outliers in minutes and nutrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 160 recipes with invalid cook times\n",
      "Calories capped at 99th percentile: 2967.5\n"
     ]
    }
   ],
   "source": [
    "# Remove recipes with 0 or unreasonably high cook times (> 1 week = 10080 min)\n",
    "before = len(recipes)\n",
    "recipes = recipes[(recipes['minutes'] > 0) & (recipes['minutes'] <= 10080)]\n",
    "print(f'Removed {before - len(recipes)} recipes with invalid cook times')\n",
    "\n",
    "# Cap extreme calorie values at 99th percentile\n",
    "cal_99 = recipes['calories'].quantile(0.99)\n",
    "recipes['calories'] = recipes['calories'].clip(upper=cal_99)\n",
    "print(f'Calories capped at 99th percentile: {cal_99:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4e. Drop unused columns and handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining recipe columns:\n",
      "['name', 'recipe_id', 'minutes', 'contributor_id', 'submitted', 'tags', 'n_steps', 'description', 'ingredients', 'n_ingredients', 'calories', 'total_fat_pdv', 'sugar_pdv', 'sodium_pdv', 'protein_pdv', 'sat_fat_pdv', 'carbs_pdv']\n",
      "\n",
      "Missing values:\n",
      "name              0\n",
      "recipe_id         0\n",
      "minutes           0\n",
      "contributor_id    0\n",
      "submitted         0\n",
      "tags              0\n",
      "n_steps           0\n",
      "description       0\n",
      "ingredients       0\n",
      "n_ingredients     0\n",
      "calories          0\n",
      "total_fat_pdv     0\n",
      "sugar_pdv         0\n",
      "sodium_pdv        0\n",
      "protein_pdv       0\n",
      "sat_fat_pdv       0\n",
      "carbs_pdv         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop raw nutrition string (already parsed) and steps (not needed for CF)\n",
    "recipes = recipes.drop(columns=['nutrition', 'steps'])\n",
    "\n",
    "# Fill missing descriptions with empty string\n",
    "recipes['description'] = recipes['description'].fillna('')\n",
    "\n",
    "# Rename 'id' to 'recipe_id' for consistency with interactions\n",
    "recipes = recipes.rename(columns={'id': 'recipe_id'})\n",
    "\n",
    "print('Remaining recipe columns:')\n",
    "print(recipes.columns.tolist())\n",
    "print(f'\\nMissing values:')\n",
    "print(recipes.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Final Alignment Check\n",
    "\n",
    "Make sure every recipe_id in interactions has a corresponding row in recipes (and vice versa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe IDs in interactions but not in recipes: 160\n",
      "Recipe IDs in recipes but not in interactions: 0\n",
      "Removing mismatched interactions...\n",
      "Interactions after alignment: 469,637\n",
      "\n",
      "Alignment OK.\n"
     ]
    }
   ],
   "source": [
    "interaction_recipe_ids = set(interactions_filtered['recipe_id'].unique())\n",
    "recipe_ids             = set(recipes['recipe_id'].unique())\n",
    "\n",
    "in_interactions_not_recipes = interaction_recipe_ids - recipe_ids\n",
    "in_recipes_not_interactions = recipe_ids - interaction_recipe_ids\n",
    "\n",
    "print(f'Recipe IDs in interactions but not in recipes: {len(in_interactions_not_recipes)}')\n",
    "print(f'Recipe IDs in recipes but not in interactions: {len(in_recipes_not_interactions)}')\n",
    "\n",
    "# If any mismatch, remove those interactions\n",
    "if in_interactions_not_recipes:\n",
    "    print('Removing mismatched interactions...')\n",
    "    interactions_filtered = interactions_filtered[\n",
    "        interactions_filtered['recipe_id'].isin(recipe_ids)\n",
    "    ]\n",
    "    print(f'Interactions after alignment: {len(interactions_filtered):,}')\n",
    "\n",
    "print('\\nAlignment OK.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create User and Item ID Mappings\n",
    "\n",
    "Many CF libraries (including Surprise) work better with contiguous integer IDs. We create mappings here and store them for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users:   9,087\n",
      "Number of recipes: 36,756\n",
      "\n",
      "Sample mapping (user_id → user_idx):\n",
      "{np.int64(1533): 0, np.int64(1535): 1, np.int64(1634): 2, np.int64(1676): 3, np.int64(1792): 4}\n"
     ]
    }
   ],
   "source": [
    "# Map original IDs to 0-indexed integers\n",
    "unique_users   = sorted(interactions_filtered['user_id'].unique())\n",
    "unique_recipes = sorted(interactions_filtered['recipe_id'].unique())\n",
    "\n",
    "user2idx   = {uid: idx for idx, uid in enumerate(unique_users)}\n",
    "recipe2idx = {rid: idx for idx, rid in enumerate(unique_recipes)}\n",
    "idx2user   = {v: k for k, v in user2idx.items()}\n",
    "idx2recipe = {v: k for k, v in recipe2idx.items()}\n",
    "\n",
    "interactions_filtered['user_idx']   = interactions_filtered['user_id'].map(user2idx)\n",
    "interactions_filtered['recipe_idx'] = interactions_filtered['recipe_id'].map(recipe2idx)\n",
    "\n",
    "print(f'Number of users:   {len(unique_users):,}')\n",
    "print(f'Number of recipes: {len(unique_recipes):,}')\n",
    "print('\\nSample mapping (user_id → user_idx):')\n",
    "print(dict(list(user2idx.items())[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Sparsity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Processed Dataset Stats ===\n",
      "  Users:       9,087\n",
      "  Recipes:     36,756\n",
      "  Ratings:     469,637\n",
      "  Sparsity:    99.8594%\n",
      "  Rating mean: 4.73\n",
      "  Rating std:  0.59\n"
     ]
    }
   ],
   "source": [
    "n_users   = len(unique_users)\n",
    "n_recipes = len(unique_recipes)\n",
    "n_ratings = len(interactions_filtered)\n",
    "sparsity  = 1 - (n_ratings / (n_users * n_recipes))\n",
    "\n",
    "print('=== Final Processed Dataset Stats ===')\n",
    "print(f'  Users:       {n_users:,}')\n",
    "print(f'  Recipes:     {n_recipes:,}')\n",
    "print(f'  Ratings:     {n_ratings:,}')\n",
    "print(f'  Sparsity:    {sparsity*100:.4f}%')\n",
    "print(f'  Rating mean: {interactions_filtered[\"rating\"].mean():.2f}')\n",
    "print(f'  Rating std:  {interactions_filtered[\"rating\"].std():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved interactions_clean.csv — 469,637 rows\n",
      "Saved recipes_clean.csv      — 36,756 rows\n",
      "Saved user_mapping.csv and recipe_mapping.csv\n"
     ]
    }
   ],
   "source": [
    "# Save interactions (only keep columns we need)\n",
    "interactions_out = interactions_filtered[['user_id', 'recipe_id', 'rating', 'date', 'user_idx', 'recipe_idx']]\n",
    "interactions_out.to_csv('../data/processed/interactions_clean.csv', index=False)\n",
    "print(f'Saved interactions_clean.csv — {len(interactions_out):,} rows')\n",
    "\n",
    "# Save recipes — store ingredients and tags as pipe-separated strings\n",
    "# (easier to reload than stringified lists)\n",
    "recipes_out = recipes.copy()\n",
    "recipes_out['ingredients'] = recipes_out['ingredients'].apply(lambda x: '|'.join(x))\n",
    "recipes_out['tags']        = recipes_out['tags'].apply(lambda x: '|'.join(x))\n",
    "recipes_out.to_csv('../data/processed/recipes_clean.csv', index=False)\n",
    "print(f'Saved recipes_clean.csv      — {len(recipes_out):,} rows')\n",
    "\n",
    "# Save ID mappings\n",
    "pd.DataFrame(list(user2idx.items()), columns=['user_id', 'user_idx']).to_csv(\n",
    "    '../data/processed/user_mapping.csv', index=False)\n",
    "pd.DataFrame(list(recipe2idx.items()), columns=['recipe_id', 'recipe_idx']).to_csv(\n",
    "    '../data/processed/recipe_mapping.csv', index=False)\n",
    "print('Saved user_mapping.csv and recipe_mapping.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Quick Sanity Check on Saved Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Reloaded interactions_clean.csv ===\n",
      "(469637, 6)\n",
      "      user_id  recipe_id  rating        date  user_idx  recipe_idx\n",
      "0      226867     363072       5  2018-12-18      3472       33295\n",
      "1     1290903     131607       5  2018-12-18      8508       17700\n",
      "2  2001513060     192495       5  2018-12-17      9082       23370\n",
      "\n",
      "=== Reloaded recipes_clean.csv ===\n",
      "(36756, 17)\n",
      "   recipe_id                              name  \\\n",
      "0      63986  chicken lickin  good  pork chops   \n",
      "1      43026                    chile rellenos   \n",
      "2      23933                    chinese  candy   \n",
      "\n",
      "                                         ingredients  \\\n",
      "0  lean pork chops|flour|salt|dry mustard|garlic ...   \n",
      "1  egg roll wrap|whole green chilies|cheese|corns...   \n",
      "2  butterscotch chips|chinese noodles|salted peanuts   \n",
      "\n",
      "                                                tags  \n",
      "0  weeknight|time-to-make|course|main-ingredient|...  \n",
      "1  60-minutes-or-less|time-to-make|course|main-in...  \n",
      "2  15-minutes-or-less|time-to-make|course|prepara...  \n"
     ]
    }
   ],
   "source": [
    "# Reload and verify\n",
    "check_interactions = pd.read_csv('../data/processed/interactions_clean.csv')\n",
    "check_recipes      = pd.read_csv('../data/processed/recipes_clean.csv')\n",
    "\n",
    "print('=== Reloaded interactions_clean.csv ===')\n",
    "print(check_interactions.shape)\n",
    "print(check_interactions.head(3))\n",
    "\n",
    "print('\\n=== Reloaded recipes_clean.csv ===')\n",
    "print(check_recipes.shape)\n",
    "print(check_recipes[['recipe_id', 'name', 'ingredients', 'tags']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Step | Action |\n",
    "|---|---|\n",
    "| Remove zero ratings | Dropped interactions with `rating == 0` |\n",
    "| Remove duplicates | Kept most recent rating per user-recipe pair |\n",
    "| Filter users | Kept users with ≥ 10 ratings (iterative) |\n",
    "| Filter recipes | Kept recipes with ≥ 5 ratings (iterative) |\n",
    "| Parse ingredients/tags | `ast.literal_eval` → pipe-separated strings |\n",
    "| Parse nutrition | Expanded into 7 named columns |\n",
    "| Outlier handling | Removed 0-minute and >10080-minute recipes, capped calories |\n",
    "| ID mappings | Created `user_idx` and `recipe_idx` for CF model |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
